{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tycjJ86fgPmy",
        "colab_type": "text"
      },
      "source": [
        "#Human Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJB-GpOFZeJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from math import *\n",
        "from PIL import Image\n",
        "from copy import deepcopy\n",
        "from scipy.misc import imsave\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ9rPotUZi4_",
        "colab_type": "code",
        "outputId": "3fa89ae7-ebf9-441c-8564-8deb4f1c92c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeUqsvNFZtnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vector_for_cell(cell_M,cell_Theta,centres):\n",
        "  #This function takes the cell gradient magnitude and gradient angle as input and generates 9 bins\n",
        "  #corresponding to that cell and returns it\n",
        "  \n",
        "  res = [0 for i in range(9)]\n",
        "  \n",
        "  for u in range(8):\n",
        "    for v in range(8):\n",
        "      \n",
        "      if cell_Theta[u,v]>160:\n",
        "        res[-1] += ((20-(cell_Theta[u,v]-160))*cell_M[u,v])/20.0\n",
        "        res[0] += ((cell_Theta[u,v]-160)*cell_M[u,v])/20.0\n",
        "  \n",
        "      elif cell_Theta[u,v]<0:\n",
        "        res[0] += ((20-(0-cell_Theta[u,v]))*cell_M[u,v])/20.0\n",
        "        res[-1] += ((0-cell_Theta[u,v])*cell_M[u,v])/20.0\n",
        "    \n",
        "      else:\n",
        "        dist = []\n",
        "        for x in range(len(centres)):\n",
        "          dist.append((x,abs(centres[x]-cell_Theta[u,v])))\n",
        "\n",
        "        dist.sort(key = lambda arr: arr[1]) \n",
        "\n",
        "        l = dist[:2]\n",
        "\n",
        "\n",
        "        res[l[0][0]] += float(cell_M[u,v]*l[1][1])/20.0\n",
        "        res[l[1][0]] += float(cell_M[u,v]*l[0][1])/20.0\n",
        "    \n",
        "  return res\n",
        "\n",
        "\n",
        "def L2_norm(arr):\n",
        "  #This function is used for L2 block normalization\n",
        "  res = 0\n",
        "  for ele in arr:\n",
        "    res += (ele)**2\n",
        "  return res**(0.5)\n",
        "\n",
        "\n",
        "def flatten(arr):\n",
        "  #This function is used to flatten 3d array to 1d array\n",
        "  #This function is called to concatenate descriptors of 4 adjacent cells into one \n",
        "  #and also concatenate descriptors of all blocks into HOG descriptor\n",
        "  res = []\n",
        "  for u in range(arr.shape[0]):\n",
        "    for v in range(arr.shape[1]):\n",
        "      res += arr[u,v].tolist()\n",
        "      \n",
        "  return np.array(res)\n",
        "\n",
        "\n",
        "\n",
        "def relu(arr):\n",
        "  #This is the relu activation function used for hidden layer neurons\n",
        "  res = deepcopy(arr)\n",
        "  res[res<0]=0\n",
        "  return res\n",
        "\n",
        "def sigmoid(arr):\n",
        "  #This is the sigmoid activation function for outer layer neuron\n",
        "  return 1.0/(1+np.exp(-arr))\n",
        "\n",
        "def MSE(arr1,arr2):\n",
        "  #This function is used to find squared error\n",
        "  return (0.5*(arr1-arr2)**2).sum()\n",
        "\n",
        "def MSE_grad(arr1,arr2):\n",
        "  #This function is the gradient of squared error function and is used during backpropagation\n",
        "  return (arr2-arr1)\n",
        "\n",
        "def sigmoid_grad(arr):\n",
        "  #This function is the gradient of sigmoid activation function and is used during backpropagation\n",
        "  return np.multiply(sigmoid(arr),1-sigmoid(arr))\n",
        "\n",
        "def relu_grad(a):\n",
        "  #This function is the gradient of relu activation function and is used during backpropagation\n",
        "  arr = deepcopy(a)\n",
        "  arr[arr<0]=0\n",
        "  arr[arr>0]=1\n",
        "  return arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCaugvbAaGmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rgb_to_gray_img(rgb_image):\n",
        "  #This function converts an RGB image to grayscale one\n",
        "  grayscale_image = np.zeros((rgb_image.shape[0],rgb_image.shape[1]))\n",
        "  for i in range(rgb_image.shape[0]):\n",
        "    for j in range(rgb_image.shape[1]):\n",
        "        r,g,b= rgb_image[i,j]\n",
        "        I = round(0.299*r + 0.587*g + 0.114*b)\n",
        "        grayscale_image[i,j] = I\n",
        "  return grayscale_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6OizGDrbEx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_horizontal_and_vertical_gradients(grayscale_image):\n",
        "  #This function returns the horizontal and vertical gradients of the grayscale_image\n",
        "  Gx = np.zeros((grayscale_image.shape[0],grayscale_image.shape[1]))\n",
        "  Gy = np.zeros((grayscale_image.shape[0],grayscale_image.shape[1]))\n",
        "  Gx_mask = np.matrix([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
        "  Gy_mask = np.matrix([[1,1,1],[0,0,0],[-1,-1,-1]])\n",
        "\n",
        "\n",
        "  for i in range(1,grayscale_image.shape[0]-1):            \n",
        "      for j in range(1,grayscale_image.shape[1]-1):\n",
        "        Gx[i,j] = (np.multiply(grayscale_image[i-1:i+2,j-1:j+2],Gx_mask).sum())\n",
        "        Gy[i,j] = (np.multiply(grayscale_image[i-1:i+2,j-1:j+2],Gy_mask).sum())\n",
        "\n",
        "\n",
        "  Gx = np.array(Gx)\n",
        "  Gy = np.array(Gy)\n",
        "  return [Gx,Gy]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtDNgir9bkBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_magnitude_and_gradient_angle(Gx,Gy):\n",
        "  #This function returns the Normalized Gradient Magnitude and Gradient angles(in degrees) corresponding to \n",
        "  #the horizontal and vertical gradients of the grayscale_image\n",
        "  M = np.zeros((Gx.shape[0],Gx.shape[1]))\n",
        "  Theta = np.zeros((Gx.shape[0],Gx.shape[1]))\n",
        "\n",
        "  for i in range(1,Gx.shape[0]-1):            \n",
        "      for j in range(1,Gx.shape[1]-1):\n",
        "        M[i,j] = sqrt((Gx[i,j])**2 + (Gy[i,j])**2)\n",
        "        if Gx[i,j]==0 and Gy[i,j]==0:               #If both Gx and Gy are 0 then gradient angle is 0 degrees\n",
        "          t = 0\n",
        "        elif Gx[i,j] == 0:                            # This is to solve divide by 0 error\n",
        "           t = 90                                   # If only Gx is 0, gradient angle is 90 degrees\n",
        "        else:\n",
        "          t = degrees(np.arctan(Gy[i,j]*1.0/Gx[i,j]))\n",
        "          if t<0:                                   # All negative angles are shifted\n",
        "            t += 180                                # to the range of 90 and 180 degrees this range is [0,180)\n",
        "        if t>=170:                        #This is done to get the gradient angle range from [0,180)                            \n",
        "          t -= 180                        #to [-10,170). This is achieved by subtracting 180 from all angles \n",
        "        Theta[i,j] = t                    # greater than or equal to 170\n",
        "\n",
        "  M = np.array(M)\n",
        "  Theta = np.array(Theta)\n",
        "  return [M,Theta]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__wgPutjb6a6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cells(M,Theta):\n",
        "  #This function generates a 2d array of cells, with each element being a bin of length 9\n",
        "  cells = [[[0 for k in range(9)] for j in range(M.shape[1]/8)] for i in range(M.shape[0]/8)]\n",
        "  for i in range(0,M.shape[0],8):\n",
        "    for j in range(0,M.shape[1],8):\n",
        "      cell_M = M[i:i+8,j:j+8]\n",
        "      cell_Theta = Theta[i:i+8,j:j+8]\n",
        "\n",
        "      cells[i/8][j/8] = get_vector_for_cell(cell_M,cell_Theta,[(c*20) for c in range(9)])\n",
        "  cells = np.array(cells)\n",
        "  return cells"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0rhDpsedJgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_blocks(cells):\n",
        "  #This function generates a 2d array of block, with each element being a descriptor of length 36\n",
        "  blocks = [[[0 for k in range(36)] for j in range(cells.shape[1]-1)] for i in range(cells.shape[0]-1)]\n",
        "  for i in range(0,cells.shape[0]-1):\n",
        "    for j in range(0,cells.shape[1]-1):\n",
        "\n",
        "      temp = flatten(cells[i:i+2,j:j+2])\n",
        "      if float(L2_norm(temp)) != 0:\n",
        "        blocks[i][j] = (temp/float(L2_norm(temp))).tolist()\n",
        "\n",
        "  blocks = np.array(blocks)\n",
        "  return blocks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIszTFfSfMRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_final_descriptor_from_blocks(blocks):\n",
        "  #This function generates the HOG descriptor of length 7524 by flattening/concatenating all the block descriptors\n",
        "  return flatten(blocks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQXmwlpdQX77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_final_descriptor(images):\n",
        "  #This function generates HOG descriptor for each image from the list of images\n",
        "  # and creates a 2d array, where each row corresponds to an image and 7524 columns representing HOG descriptors\n",
        "  final_descriptors1 = []\n",
        "  \n",
        "  for i in range(len(images)):\n",
        "    rgb_image1 = images[i]\n",
        "    grayscale_image1 = rgb_to_gray_img(rgb_image1)\n",
        "    Gx1 , Gy1 = get_horizontal_and_vertical_gradients(grayscale_image1)\n",
        "    M1 , Theta1 = get_magnitude_and_gradient_angle(Gx1,Gy1)\n",
        "    if len(images)==10:\n",
        "      imsave('Test_{}.bmp'.format(i), np.array(M1))\n",
        "    cells1 = get_cells(M1,Theta1)\n",
        "    blocks1 = get_blocks(cells1)\n",
        "    final_descriptor1 = get_final_descriptor_from_blocks(blocks1)\n",
        "    if len(images)==20 and i==5:\n",
        "      np.savetxt('HogDescriptor_crop001278a.txt', final_descriptor1, delimiter='\\n')\n",
        "    elif len(images)==10 and i==2:\n",
        "      np.savetxt('HogDescriptor_crop001045b.txt', final_descriptor1, delimiter='\\n')     \n",
        "    final_descriptors1.append(final_descriptor1)\n",
        "  final_descriptors1 = np.array(final_descriptors1)\n",
        "  return final_descriptors1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFhlBBiIsIGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weights(input_layer_neurons,hidden_layer_neurons):\n",
        "  #Random initialization of weights and bias\n",
        "  w = np.random.normal(0, 0.1, size=(input_layer_neurons, hidden_layer_neurons))\n",
        "  v = np.random.normal(0, 0.1, size=(hidden_layer_neurons, 1))\n",
        "\n",
        "  b1 = np.random.normal(0, 0.1, size=(1,hidden_layer_neurons))\n",
        "  b2 = np.random.normal(0, 0.1, size=(1,1))\n",
        "  return [w,v,b1,b2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6tiZ4sLsZGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(X,y_actual,w,v,b1,b2,lr):\n",
        "  #This function is for training the Multi Layer Perceptron Model on the given training data and random weights and bias\n",
        "  #This function returns the epochs,Error,updated weights and bias when the Errors in two consecutive epochs are same after \n",
        "  #rounding them to 5 places after decimal\n",
        "  epochs = 0\n",
        "  E_prev = float('inf')\n",
        "  while True:\n",
        "    E = 0\n",
        "    for i in range(X.shape[0]):\n",
        "      x = X[i].reshape(1,-1) \n",
        "      z = np.dot(x,w) + b1\n",
        "      z = relu(z)\n",
        "\n",
        "      y = np.dot(z,v) + b2\n",
        "      y = sigmoid(y)\n",
        "      E += MSE(y_actual[i],y)\n",
        "\n",
        "      grad = MSE_grad(y_actual[i],y)\n",
        "      grad = np.multiply(grad,sigmoid_grad(y))\n",
        "      vd = np.dot(grad.T,z).T\n",
        "      b2d = np.dot(grad.T,np.ones((z.shape[0],1))).T\n",
        "\n",
        "      grad = np.dot(grad,v.T)\n",
        "      v -= lr*vd\n",
        "      b2 -= lr*b2d \n",
        "\n",
        "      grad = np.multiply(grad,relu_grad(z))\n",
        "      wd = np.dot(grad.T,x).T\n",
        "      b1d = np.dot(grad.T,np.ones((x.shape[0],1))).T\n",
        "\n",
        "      grad = np.dot(grad,w.T)\n",
        "      w -= lr*wd\n",
        "      b1 -= lr*b1d\n",
        "    epochs += 1\n",
        "    if round(E,5) == round(E_prev,5):\n",
        "      return [epochs,E,w,v,b1,b2]\n",
        "    else:\n",
        "      E_prev = E\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ii7_dC8tOQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(X,w,v,b1,b2):\n",
        "  #This function is used to test the images and generate output after applying sigmoid activation function\n",
        "  z = np.dot(X,w) + b1\n",
        "  z = relu(z)\n",
        "  y = np.dot(z,v) + b2\n",
        "  y = sigmoid(y)\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV4-ctbKp2jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = [cv2.imread(file) for file in glob.glob(\"/content/drive/My Drive/Human/Train_Positive/*.bmp\")]\n",
        "train_images += [cv2.imread(file) for file in glob.glob(\"/content/drive/My Drive/Human/Train_Negative/*.bmp\")]\n",
        "train_final_descriptors = get_final_descriptor(train_images)\n",
        "\n",
        "\n",
        "test_images = [cv2.imread(file) for file in glob.glob(\"/content/drive/My Drive/Human/Test_Positive/*.bmp\")]\n",
        "test_images += [cv2.imread(file) for file in glob.glob(\"/content/drive/My Drive/Human/Test_Neg/*.bmp\")]\n",
        "test_final_descriptors = get_final_descriptor(test_images)\n",
        "\n",
        "\n",
        "y_train = np.array([1 for i in range(10)]+[0 for i in range(10)]).reshape(-1,1)\n",
        "y_test = np.array([1 for i in range(5)]+[0 for i in range(5)]).reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0F9wBDWqh0o",
        "colab_type": "text"
      },
      "source": [
        "##Classification of test images for different learning rates :-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41YW1WDHqePx",
        "colab_type": "text"
      },
      "source": [
        "###When learning rate = 0.2,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf6r2PUKUG1Y",
        "colab_type": "code",
        "outputId": "82158e2b-9499-4fd8-b66e-9209ea15260f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "for hidden_layer_neurons in [250,500,1000]:\n",
        "  print 'For {} hidden layer neurons,'.format(hidden_layer_neurons)\n",
        "  w,v,b1,b2 = get_weights(train_final_descriptors.shape[1],hidden_layer_neurons)\n",
        "  epochs,E,w,v,b1,b2 = training(train_final_descriptors,y_train,w,v,b1,b2,0.18)\n",
        "  y_pred = testing(test_final_descriptors,w,v,b1,b2)\n",
        "  print 'Epochs = {}'.format(epochs)\n",
        "  print 'Error = {}'.format(E)\n",
        "  print 'Output value = {}'.format(y_pred.reshape(1,-1))\n",
        "  y_pred[y_pred>=0.5]=1\n",
        "  y_pred[y_pred<0.5]=0\n",
        "  print 'Classification = {}'.format(y_pred.reshape(1,-1))\n",
        "  print 'Accuracy = {}%'.format((y_pred[y_pred==y_test].shape[0])*100.0/y_pred.shape[0])\n",
        "  print '\\n'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For 250 hidden layer neurons,\n",
            "Epochs = 13\n",
            "Error = 2.05342006981e-05\n",
            "Output value = [[0.93257423 0.99993987 0.57244634 0.97617415 0.05211053 0.20249758\n",
            "  0.04281609 0.00148125 0.04123898 0.09247734]]\n",
            "Classification = [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "Accuracy = 90.0%\n",
            "\n",
            "\n",
            "For 500 hidden layer neurons,\n",
            "Epochs = 14\n",
            "Error = 7.87607452205e-06\n",
            "Output value = [[9.94477900e-01 9.99993858e-01 9.90142280e-01 9.91103416e-01\n",
            "  9.20436497e-02 1.15706431e-01 2.58671639e-02 3.65888089e-05\n",
            "  2.15566512e-02 4.06752746e-02]]\n",
            "Classification = [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "Accuracy = 90.0%\n",
            "\n",
            "\n",
            "For 1000 hidden layer neurons,\n",
            "Epochs = 12\n",
            "Error = 1.82191539945e-06\n",
            "Output value = [[9.99996453e-01 1.00000000e+00 9.99999991e-01 9.99999718e-01\n",
            "  5.01915777e-02 1.53693468e-01 1.36580560e-01 6.31815219e-11\n",
            "  2.49422285e-01 2.09296777e-04]]\n",
            "Classification = [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "Accuracy = 90.0%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUjSLXkEqwKL",
        "colab_type": "text"
      },
      "source": [
        "###When learning rate = 0.1,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpqJMH7S8nkd",
        "colab_type": "code",
        "outputId": "26e91510-2b72-4eee-d1b2-680deb1d3229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "for hidden_layer_neurons in [250,500,1000]:\n",
        "  print 'For {} hidden layer neurons,'.format(hidden_layer_neurons)\n",
        "  w,v,b1,b2 = get_weights(train_final_descriptors.shape[1],hidden_layer_neurons)\n",
        "  epochs,E,w,v,b1,b2 = training(train_final_descriptors,y_train,w,v,b1,b2,0.1)\n",
        "  y_pred = testing(test_final_descriptors,w,v,b1,b2)\n",
        "  print 'Epochs = {}'.format(epochs)\n",
        "  print 'Error = {}'.format(E)\n",
        "  print 'Output value = {}'.format(y_pred.reshape(1,-1))\n",
        "  y_pred[y_pred>=0.5]=1\n",
        "  y_pred[y_pred<0.5]=0\n",
        "  print 'Classification = {}'.format(y_pred.reshape(1,-1))\n",
        "  print 'Actual Labels = {}'.format(y_test.reshape(1,-1))\n",
        "  print 'Accuracy = {}%'.format((y_pred[y_pred==y_test].shape[0])*100.0/y_pred.shape[0])\n",
        "  print '\\n'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For 250 hidden layer neurons,\n",
            "Epochs = 55\n",
            "Error = 1.95579233576e-05\n",
            "Output value = [[0.85104257 0.9976786  0.96697477 0.93677706 0.11415916 0.28361686\n",
            "  0.11297893 0.00496342 0.38637148 0.07748381]]\n",
            "Classification = [[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "Actual Labels = [[1 1 1 1 1 0 0 0 0 0]]\n",
            "Accuracy = 90.0%\n",
            "\n",
            "\n",
            "For 500 hidden layer neurons,\n",
            "Epochs = 12\n",
            "Error = 2.01414542303e-08\n",
            "Output value = [[8.43173744e-01 9.99989284e-01 9.94938749e-01 9.99798024e-01\n",
            "  6.39347672e-01 3.94389500e-02 4.18083709e-02 4.66437368e-05\n",
            "  4.41191969e-02 1.23899519e-02]]\n",
            "Classification = [[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "Actual Labels = [[1 1 1 1 1 0 0 0 0 0]]\n",
            "Accuracy = 100.0%\n",
            "\n",
            "\n",
            "For 1000 hidden layer neurons,\n",
            "Epochs = 22\n",
            "Error = 4.74492349554e-06\n",
            "Output value = [[9.99989451e-01 9.99999984e-01 9.87248432e-01 9.99996573e-01\n",
            "  9.96177490e-01 6.26905812e-02 1.13085164e-01 2.76787401e-06\n",
            "  7.17418612e-01 7.96958751e-02]]\n",
            "Classification = [[1. 1. 1. 1. 1. 0. 0. 0. 1. 0.]]\n",
            "Actual Labels = [[1 1 1 1 1 0 0 0 0 0]]\n",
            "Accuracy = 90.0%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CbvlI6jq11i",
        "colab_type": "text"
      },
      "source": [
        "###When learning rate = 0.15,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3etI-Tr3_tl",
        "colab_type": "code",
        "outputId": "84b82df8-41e6-436a-d5cc-65e9fbcb97fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "for hidden_layer_neurons in [250,500,1000]:\n",
        "  print 'For {} hidden layer neurons,'.format(hidden_layer_neurons)\n",
        "  w,v,b1,b2 = get_weights(train_final_descriptors.shape[1],hidden_layer_neurons)\n",
        "  epochs,E,w,v,b1,b2 = training(train_final_descriptors,y_train,w,v,b1,b2,0.15)\n",
        "  y_pred = testing(test_final_descriptors,w,v,b1,b2)\n",
        "  print 'Epochs = {}'.format(epochs)\n",
        "  print 'Error = {}'.format(E)\n",
        "  print 'Output value = {}'.format(y_pred.reshape(1,-1))\n",
        "  y_pred[y_pred>=0.5]=1\n",
        "  y_pred[y_pred<0.5]=0\n",
        "  print 'Classification = {}'.format(y_pred.reshape(1,-1))\n",
        "  print 'Accuracy = {}%'.format((y_pred[y_pred==y_test].shape[0])*100.0/y_pred.shape[0])\n",
        "  print '\\n'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For 250 hidden layer neurons,\n",
            "Epochs = 11\n",
            "Error = 0.000418618359343\n",
            "Output value = [[0.97437874 0.99993694 0.97535996 0.99738982 0.53089917 0.0665184\n",
            "  0.09006134 0.00396099 0.29947957 0.17736695]]\n",
            "Classification = [[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "Accuracy = 100.0%\n",
            "\n",
            "\n",
            "For 500 hidden layer neurons,\n",
            "Epochs = 11\n",
            "Error = 9.12175710951e-05\n",
            "Output value = [[8.80168510e-01 9.99951945e-01 9.97560409e-01 9.98920623e-01\n",
            "  8.98300273e-01 3.00897247e-02 5.59561419e-02 9.41292797e-04\n",
            "  1.63365534e-02 2.05094362e-02]]\n",
            "Classification = [[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "Accuracy = 100.0%\n",
            "\n",
            "\n",
            "For 1000 hidden layer neurons,\n",
            "Epochs = 12\n",
            "Error = 2.62123226867e-14\n",
            "Output value = [[9.99997716e-01 1.00000000e+00 9.99999994e-01 9.99999999e-01\n",
            "  9.99172011e-01 7.66887747e-04 3.82090427e-02 3.67318407e-10\n",
            "  3.83665307e-02 7.78593579e-04]]\n",
            "Classification = [[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.]]\n",
            "Accuracy = 100.0%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}